<html>
  <head>
    <!-- Load TensorFlow.js -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"> </script>

    <script>
      tf.loadLayersModel('https://raw.githubusercontent.com/khvmaths/khvmaths.github.io/master/model.json')
        .then(function (model) {
          console.log(model)
          const webrtcElement = document.getElementById("gum-local");
          window.requestAnimationFrame(onFrame.bind(null, model, webrtcElement));
        })
      // const model = await tf.loadModel('localstorage://model.json');
      // const webrtcElement = document.getElementById("gum-local");
      // window.requestAnimationFrame(onFrame.bind(null, model, webrtcElement));

      
      function onFrame(model, webrtcElement) {
        if(document.getElementById("gum-local").readyState ===4){
        const tensor = tf.browser.fromPixels(webrtcElement);
        const eTensor = tensor.expandDims(0).asType('float32').div(256.0);
        const pred = model.predict(eTensor);
        max = tf.argMax(pred, 1)
        const index = max.get([0])
        const label = imagenetLabels[index]
        const labelElement = document.getElementById("label");
        labelElement.innerHTML = label
        window.requestAnimationFrame(onFrame.bind(null, model, webrtcElement));
      }}

      const imagenetLabels = {
        0:'A',
        1:'B',
        2:'C'}


      /////////////////
      // WEBRTC

      // Put variables in global scope to make them available to the browser console.
      const constraints = window.constraints = {
        audio: false,
        video: {VideoConstraints.facingMode = 'environment';}
      };

      function handleSuccess(stream) {
        const video = document.querySelector('video');
        const videoTracks = stream.getVideoTracks();
        console.log('Got stream with constraints:', constraints);
        console.log(`Using video device: ${videoTracks[0].label}`);
        window.stream = stream; // make variable available to browser console
        video.srcObject = stream;
      }

      function handleError(error) {
        if (error.name === 'ConstraintNotSatisfiedError') {
          let v = constraints.video;
          errorMsg(`The resolution ${v.width.exact}x${v.height.exact} px is not supported by your device.`);
        } else if (error.name === 'PermissionDeniedError') {
          errorMsg('Permissions have not been granted to use your camera and ' +
            'microphone, you need to allow the page access to your devices in ' +
            'order for the demo to work.');
        }
        errorMsg(`getUserMedia error: ${error.name}`, error);
      }

      function errorMsg(msg, error) {
        const errorElement = document.querySelector('#errorMsg');
        errorElement.innerHTML += `<p>${msg}</p>`;
        if (typeof error !== 'undefined') {
          console.error(error);
        }
      }

      navigator.mediaDevices
        .getUserMedia(constraints)
        .then(handleSuccess)
        .catch(handleError);
    </script>
  </head>

  <body>
      <video id="gum-local" width="300" height="300" autoPlay playsinline></video>
      <div id="label"></div>
      <div id="errorMsg"></div>
  </body>
</html>
